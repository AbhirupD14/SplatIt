Day 1
-----

Research paper for reference to 3D Gaussian Splatting:
https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/

Start of project. First step is thinking about how the internals of the library will work.

Info on hiding internals of script that should not be accessible:
https://stackoverflow.com/questions/36008595/how-to-design-a-library-public-api-avoiding-to-expose-internals


Plan is to create a class that holds all the methods and expose only the method that generates the output file given the recording path.

Day 2
-----

Working on frame extraction. Need to turn the video into a depth map to generate the point cloud from SFM. Depth map will allow 
for mapping from 2D space to 3D space for the point cloud. 

Tools for frame extraction:

OpenCV

Tools for depth map generation:
torchvision

Day 3
-----

Just researched more on point clouds and depth maps. Nothing added to code.

Day 4
-----

Reseraching SfM (Structure from Motion). Looking into source videos to feed into program.

Day 5
-----
Added code to generate depth maps. Needs revision but rough idea is there. Need to move on to generate point clouds. Main flow is as follows:

First the video is taken in and a directory is created called frames. This directory will hold a jpg for each frame. The directory will be loaded into an array
from which a depth map for each frame is generated. Each map is stored in another list which is passed to the point cloud generation function.
The point cloud generation function will take each depth map and make point clouds, aligning them to one point cloud. This point cloud will be used 
to generate the 3D gaussians. The gaussians will be rasterized for shape and color. This should hopefully generate the scene.
